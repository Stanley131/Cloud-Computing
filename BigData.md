1. Example: compute a large file score   
    - copy the data or download the data to the machine 

2. To handle large comptation  
    -  1GB/hour 
    - 100GB? 100h?
3. Where the rubber meets the road?
    - Concurrency is difficuly to reason about

4. Big Data Motivation 
    - Google Processes 20PB a day 
    - partition work 
    - Compute by many individual mahchines 
    - combine result 
    - As a programmer, we just need to write a program. 
5. What's the point?
    - It's all about the right level of abstraction
6. How HDFS works?
    - SPARK and MapReduce
7. MR Framework
